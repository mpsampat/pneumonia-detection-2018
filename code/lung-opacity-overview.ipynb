{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cbce5cc636ba65b81d858c596e39aa532728780"
   },
   "source": [
    "# Overview\n",
    "The notebook aims to get a better feeling for the data and more importantly the distributions of values. We take the labels and combine them with the detailed class info and try and determine what the biggest challenges of the prediction might be. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "ae448b0ed29194053d40ebd29b2fa03982468552"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from matplotlib.patches import Rectangle\n",
    "det_class_path = '../input/stage_1_detailed_class_info.csv'\n",
    "bbox_path = '../input/stage_1_train_labels.csv'\n",
    "dicom_dir = '../input/stage_1_train_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f4ff05105153200d3dc3f382b5a24b6e6dd80291"
   },
   "source": [
    "# Detailed Class Info\n",
    "Here we show the image-level labels for the scans. The most interesting group here is the `No Lung Opacity / Not Normal` since they are cases that look like opacity but are not. So the first step might be to divide the test images into clear groups and then only perform the bounding box prediction on the suspicious images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "a0a43187041d2773c035b62f68a9687811f9fcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28989 class infos loaded\n",
      "25684 patient cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6563</th>\n",
       "      <td>4fd82276-a900-49e3-8282-ffda6edd6068</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22025</th>\n",
       "      <td>c78daf52-c33b-4367-a28f-5bc60a92e7d9</td>\n",
       "      <td>Lung Opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16237</th>\n",
       "      <td>9d7122f2-9b37-41cb-92f5-b4954ba23b6c</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId                         class\n",
       "6563   4fd82276-a900-49e3-8282-ffda6edd6068                  Lung Opacity\n",
       "22025  c78daf52-c33b-4367-a28f-5bc60a92e7d9                  Lung Opacity\n",
       "16237  9d7122f2-9b37-41cb-92f5-b4954ba23b6c  No Lung Opacity / Not Normal"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "det_class_df = pd.read_csv(det_class_path)\n",
    "print(det_class_df.shape[0], 'class infos loaded')\n",
    "print(det_class_df['patientId'].value_counts().shape[0], 'patient cases')\n",
    "det_class_df.groupby('class').size().plot.bar()\n",
    "det_class_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ca820c61b58fe03a613bce38c47786b8a8ef399"
   },
   "source": [
    "# Load the Bounding Box Data\n",
    "Here we show the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "cc03f5c79bee9f015c12dc8181f7997df584fbb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28989 boxes loaded\n",
      "25684 patient cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14862</th>\n",
       "      <td>9213259c-2814-4cbb-98a8-b4a21bfdf6ae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24109</th>\n",
       "      <td>d8cd7100-a106-41c7-9aa2-d1b88b789bba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20672</th>\n",
       "      <td>bca2c151-2431-4595-80c7-75480a196c6e</td>\n",
       "      <td>328.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "14862  9213259c-2814-4cbb-98a8-b4a21bfdf6ae    NaN    NaN    NaN     NaN   \n",
       "24109  d8cd7100-a106-41c7-9aa2-d1b88b789bba    NaN    NaN    NaN     NaN   \n",
       "20672  bca2c151-2431-4595-80c7-75480a196c6e  328.0  415.0  129.0   226.0   \n",
       "\n",
       "       Target  \n",
       "14862       0  \n",
       "24109       0  \n",
       "20672       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_df = pd.read_csv(bbox_path)\n",
    "print(bbox_df.shape[0], 'boxes loaded')\n",
    "print(bbox_df['patientId'].value_counts().shape[0], 'patient cases')\n",
    "bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5cc20e2eb8e9cbecf4494fe5264397438fb73a1"
   },
   "source": [
    "# Combine Boxes and Labels\n",
    "Here we bring the labels and the boxes together and now we can focus on how the boxes look on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ca18783acf240faea13a23fd06fba7b41f9ea71d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35875 combined cases\n"
     ]
    }
   ],
   "source": [
    "# we first try a join and see that it doesn't work (we end up with too many boxes)\n",
    "comb_bbox_df = pd.merge(bbox_df, det_class_df, how='inner', on='patientId')\n",
    "print(comb_bbox_df.shape[0], 'combined cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15ab554a46421da28b29d7932dcad07b5146203f"
   },
   "source": [
    "## Concatenate\n",
    "We have to concatenate the two datasets and then we get class and target information on each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "91447e135cd4525c0869692ab6a6269e5bc9f30f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28989 combined cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10764</th>\n",
       "      <td>719dd825-dd41-46f9-a59c-7385d4576196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17858</th>\n",
       "      <td>a9dbe0c0-3f75-4917-b44a-928692f5add0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>5399e1e3-a2a1-48c3-80ab-29b18ecb98f4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId   x   y  width  height  Target  \\\n",
       "10764  719dd825-dd41-46f9-a59c-7385d4576196 NaN NaN    NaN     NaN       0   \n",
       "17858  a9dbe0c0-3f75-4917-b44a-928692f5add0 NaN NaN    NaN     NaN       0   \n",
       "7020   5399e1e3-a2a1-48c3-80ab-29b18ecb98f4 NaN NaN    NaN     NaN       0   \n",
       "\n",
       "                              class  \n",
       "10764  No Lung Opacity / Not Normal  \n",
       "17858  No Lung Opacity / Not Normal  \n",
       "7020                         Normal  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_bbox_df = pd.concat([bbox_df, \n",
    "                        det_class_df.drop('patientId',1)], 1)\n",
    "print(comb_bbox_df.shape[0], 'combined cases')\n",
    "comb_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f29b7e35b8f879687bcfeadf8a93c708c94d9a7"
   },
   "source": [
    "# Distribution of Boxes and Labels\n",
    "The values below show the number of boxes and the patients that have that number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "569f38045b0359ae0635bca97dbbe600785ff565"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>boxes</th>\n",
       "      <th>patients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>22506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   boxes  patients\n",
       "0      1     22506\n",
       "1      2      3062\n",
       "2      3       105\n",
       "3      4        11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_df = comb_bbox_df.groupby('patientId').\\\n",
    "    size().\\\n",
    "    reset_index(name='boxes')\n",
    "comb_box_df = pd.merge(comb_bbox_df, box_df, on='patientId')\n",
    "box_df.\\\n",
    "    groupby('boxes').\\\n",
    "    size().\\\n",
    "    reset_index(name='patients')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "277b277b5c63562afa5a66c0714a94bb139979ec"
   },
   "source": [
    "# How are class and target related?\n",
    "I assume that all the `Target=1` values fall in the `Lung Opacity` class, but it doesn't hurt to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2386013f7461e1407f1e782865228d146264bff0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Target</th>\n",
       "      <th>Patient Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>1</td>\n",
       "      <td>8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>11500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>8525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          class  Target  Patient Count\n",
       "0                  Lung Opacity       1           8964\n",
       "1  No Lung Opacity / Not Normal       0          11500\n",
       "2                        Normal       0           8525"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_bbox_df.groupby(['class', 'Target']).size().reset_index(name='Patient Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c5c58ddf2a9a7350650586865166ae0d5ed9a0cf"
   },
   "source": [
    "# Images\n",
    "Now that we have the boxes and labels loaded we can examine a few images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "46fe765772e24397a94295a70dbde46254c4cc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25684 images found\n"
     ]
    }
   ],
   "source": [
    "image_df = pd.DataFrame({'path': glob(os.path.join(dicom_dir, '*.dcm'))})\n",
    "image_df['patientId'] = image_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "print(image_df.shape[0], 'images found')\n",
    "img_pat_ids = set(image_df['patientId'].values.tolist())\n",
    "box_pat_ids = set(comb_box_df['patientId'].values.tolist())\n",
    "# check to make sure there is no funny business\n",
    "assert img_pat_ids.union(box_pat_ids)==img_pat_ids, \"Patient IDs should be the same\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6299cf5b16c13e9eb07c69a84a934fec4cf8b6f"
   },
   "source": [
    "# Enrich the image fields\n",
    "We have quite a bit of additional data in the DICOM header we can easily extract to help learn more about the patient like their age, view position and gender which can make the model much more precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6fd8a408e2999759d3cc7500f7cb6d03d767103d"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-abe1c86d10e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtag_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimage_meta_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# show the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimage_meta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PatientAge'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_meta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PatientAge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-abe1c86d10e6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtag_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mimage_meta_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# show the summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimage_meta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PatientAge'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_meta_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PatientAge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-abe1c86d10e6>\u001b[0m in \u001b[0;36mget_tags\u001b[0;34m(in_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDCM_TAG_LIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PatientAge'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BodyPartExamined'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ViewPosition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PatientSex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mc_dicom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_before_pixels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     tag_dict = {c_tag: getattr(c_dicom, c_tag, '') \n\u001b[1;32m      5\u001b[0m          for c_tag in DCM_TAG_LIST}\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mdcmread\u001b[0;34m(fp, defer_size, stop_before_pixels, force, specific_tags)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         dataset = read_partial(fp, stop_when, defer_size=defer_size,\n\u001b[0;32m--> 886\u001b[0;31m                                force=force, specific_tags=specific_tags)\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcaller_owns_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(fileobj, stop_when, defer_size, force, specific_tags)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;31m# Read preamble (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_preamble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m     \u001b[0;31m# Read any File Meta Information group (0002,eeee) elements (if present)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0mfile_meta_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_file_meta_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pydicom/filereader.py\u001b[0m in \u001b[0;36mread_preamble\u001b[0;34m(fp, force)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m    626\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Reading File Meta Information preamble...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0mpreamble\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugging\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes2hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreamble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"...\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbytes2hex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreamble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DCM_TAG_LIST = ['PatientAge', 'BodyPartExamined', 'ViewPosition', 'PatientSex']\n",
    "def get_tags(in_path):\n",
    "    c_dicom = pydicom.read_file(in_path, stop_before_pixels=True)\n",
    "    tag_dict = {c_tag: getattr(c_dicom, c_tag, '') \n",
    "         for c_tag in DCM_TAG_LIST}\n",
    "    tag_dict['path'] = in_path\n",
    "    return pd.Series(tag_dict)\n",
    "image_meta_df = image_df.apply(lambda x: get_tags(x['path']), 1)\n",
    "# show the summary\n",
    "image_meta_df['PatientAge'] = image_meta_df['PatientAge'].map(int)\n",
    "image_meta_df['PatientAge'].hist()\n",
    "image_meta_df.drop('path',1).describe(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e42002854e4a06e6bc9ff24337b63bb42af9d2f"
   },
   "outputs": [],
   "source": [
    "image_full_df = pd.merge(image_df,\n",
    "                         image_meta_df,\n",
    "                         on='path')\n",
    "image_bbox_df = pd.merge(comb_box_df, \n",
    "                         image_full_df, \n",
    "                         on='patientId',\n",
    "                        how='left')\n",
    "print(image_bbox_df.shape[0], 'image bounding boxes')\n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "96af4bb8a61df3dd753e6b103434b996f3884c13"
   },
   "source": [
    "## Create Sample Data Set\n",
    "We create a sample dataset covering different cases, and number of boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5aa2c0ab7e7970ed26de93d66eb52cd4b08e57b6"
   },
   "outputs": [],
   "source": [
    "sample_df = image_bbox_df.\\\n",
    "    groupby(['Target','class', 'boxes']).\\\n",
    "    apply(lambda x: x[x['patientId']==x.sample(1)['patientId'].values[0]]).\\\n",
    "    reset_index(drop=True)\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e59e981d122b9a9c1c0f78d2d914775ff74f7c72"
   },
   "source": [
    "## Show the position and bounding box\n",
    "Here we can see the position (point) and the bounding box for each of the different image types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a110097202462adb9042a02cf5ce641584717043"
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize = (20, 10))\n",
    "for c_ax, (c_path, c_rows) in zip(m_axs.flatten(),\n",
    "                    sample_df.groupby(['path'])):\n",
    "    c_dicom = pydicom.read_file(c_path)\n",
    "    c_ax.imshow(c_dicom.pixel_array, cmap='bone')\n",
    "    c_ax.set_title('{class}'.format(**c_rows.iloc[0,:]))\n",
    "    for i, (_, c_row) in enumerate(c_rows.dropna().iterrows()):\n",
    "        c_ax.plot(c_row['x'], c_row['y'], 's', label='{class}'.format(**c_row))\n",
    "        c_ax.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                                width=c_row['width'],\n",
    "                                height=c_row['height'], \n",
    "                                 alpha = 0.5))\n",
    "        if i==0: c_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9cf95258eeb58aa070776fca48e620359ebb223d"
   },
   "source": [
    "# Bounding Box Distribution\n",
    "Here we just look at the bounding box distribution to get a better idea how this looks over the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0e9bb4b310379c622055f7a18a5084795ed0e10"
   },
   "outputs": [],
   "source": [
    "pos_bbox = image_bbox_df.query('Target==1')\n",
    "pos_bbox.plot.scatter(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e5a67838560247ef72e5669cdf6369b243dc998"
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax1.set_xlim(0, 1024)\n",
    "ax1.set_ylim(0, 1024)\n",
    "for _, c_row in pos_bbox.sample(1000).iterrows():\n",
    "    ax1.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                 width=c_row['width'],\n",
    "                 height=c_row['height'],\n",
    "                           alpha=5e-3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "29a114790d74a2b2794394a85045e9e94782cb3a"
   },
   "source": [
    "# Show the boxes as segmentation\n",
    "By showing them as segmentations we can get a better probability map for where the opacity regions are most likely to occur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "99d9163a94d7991d209e984d9d2b6774fc6d8a77"
   },
   "outputs": [],
   "source": [
    "# Show the boxes themselves\n",
    "X_STEPS, Y_STEPS = 1024, 1024\n",
    "xx, yy = np.meshgrid(np.linspace(0, 1024, X_STEPS),\n",
    "           np.linspace(0, 1024, Y_STEPS), \n",
    "           indexing='xy')\n",
    "prob_image = np.zeros_like(xx)\n",
    "for _, c_row in pos_bbox.sample(5000).iterrows():\n",
    "    c_mask = (xx>=c_row['x']) & (xx<=(c_row['x']+c_row['width']))\n",
    "    c_mask &= (yy>=c_row['y']) & (yy<=c_row['y']+c_row['height'])\n",
    "    prob_image += c_mask\n",
    "fig, ax1 = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax1.imshow(prob_image, cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "963b741fdb177d131af2afc6e0c4f151b014e47b"
   },
   "source": [
    "# Overlay the Probability on a few images\n",
    "Does the probability we calculate seem to make sense? or have we flipped something somewhere?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f03e4f67dbff68cedf2cc9b29ed489fe2fcdec62"
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(2, 3, figsize = (20, 10))\n",
    "for c_ax, (c_path, c_rows) in zip(m_axs.flatten(),\n",
    "                    sample_df.groupby(['path'])):\n",
    "    c_img_arr = pydicom.read_file(c_path).pixel_array\n",
    "    # overlay\n",
    "    c_img = plt.cm.gray(c_img_arr)\n",
    "    c_img += 0.25*plt.cm.hot(prob_image/prob_image.max())\n",
    "    c_img = np.clip(c_img, 0, 1)\n",
    "    c_ax.imshow(c_img)\n",
    "    \n",
    "    c_ax.set_title('{class}'.format(**c_rows.iloc[0,:]))\n",
    "    for i, (_, c_row) in enumerate(c_rows.dropna().iterrows()):\n",
    "        c_ax.plot(c_row['x'], c_row['y'], 's', label='{class}'.format(**c_row))\n",
    "        c_ax.add_patch(Rectangle(xy=(c_row['x'], c_row['y']),\n",
    "                                width=c_row['width'],\n",
    "                                height=c_row['height'], \n",
    "                                 alpha = 0.5,\n",
    "                                fill=False))\n",
    "        if i==0: c_ax.legend()\n",
    "fig.savefig('overview.png', figdpi = 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "828c1986e2f5527cce11e7d114e166454caef64e"
   },
   "source": [
    "### Save the preprocessed results\n",
    "We can use the preprocessed results with the appropriate DICOM tags to make model training step easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "497116383a76bd6285edf70c2604924f6e5e1687"
   },
   "outputs": [],
   "source": [
    "image_bbox_df.to_csv('image_bbox_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
